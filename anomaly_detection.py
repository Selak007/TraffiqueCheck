# -*- coding: utf-8 -*-
"""model.h5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1930p1UAUFPa-CM616Z_khYxrRcIawmwn
"""

import cv2
import glob
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input

# Step 1: Extract Frames
video_folder_path = r"/content/drive/MyDrive/Colab Notebooks/training_videos"  # Folder containing videos
output_folder = r"/content/output_frames"
os.makedirs(output_folder, exist_ok=True)

# Get all video file paths
video_files = glob.glob(os.path.join(video_folder_path, "*.avi"))

for video_index, video_path in enumerate(video_files):
    print(f"Processing: {video_path}")
    cap = cv2.VideoCapture(video_path)
    frame_count = 0

    video_output_folder = os.path.join(output_folder, f"video_{video_index+1}")
    os.makedirs(video_output_folder, exist_ok=True)

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_resized = cv2.resize(frame, (224, 224))
        frame_filename = os.path.join(video_output_folder, f"frame_{frame_count:04d}.jpg")
        cv2.imwrite(frame_filename, frame_resized)
        frame_count += 1

    cap.release()
    print(f"Finished processing {video_path}. Total frames: {frame_count}")

print("Frame extraction complete!")

# Step 2: Prepare Data Generators
train_data_path = output_folder  # Use the same output folder

# Assign labels manually (e.g., all frames from video_1 are class 0, video_2 are class 1)
# For simplicity, let's assume all frames belong to class 0
class_0_folder = os.path.join(train_data_path, "class_0")
os.makedirs(class_0_folder, exist_ok=True)

# Move all frames to class_0 folder
for video_folder in glob.glob(os.path.join(train_data_path, "video_*")):
    for frame_file in glob.glob(os.path.join(video_folder, "*.jpg")):
        os.rename(frame_file, os.path.join(class_0_folder, os.path.basename(frame_file)))

datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,
    validation_split=0.2
)

train_generator = datagen.flow_from_directory(
    train_data_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode="binary",  # Use "binary" for binary classification
    subset="training"
)

val_generator = datagen.flow_from_directory(
    train_data_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode="binary",  # Use "binary" for binary classification
    subset="validation"
)

# Debug: Check number of images found
print(f"Train generator found {train_generator.samples} images.")
print(f"Validation generator found {val_generator.samples} images.")

# Step 3: Define and Train the Model
model = Sequential([
    Input(shape=(224, 224, 3)),
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')  # Binary classification
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(train_generator, validation_data=val_generator, epochs=10)

print("Model training complete!")

